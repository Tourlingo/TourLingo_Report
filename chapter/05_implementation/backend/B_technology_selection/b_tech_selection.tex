\subsection{Technology Selection and Evaluation Framework}

\subsubsection{Decision Methodology}

A multi-criteria decision analysis (MCDA) approach was used to guide towards the technology selection\cite{mcda}. MCDA is a methodology to evaluate and prioritise options based on multiple potential options. The framework was used to systematically evaluate technology choices based on quantitative and qualitative factors, taking into account the system requirements and constraints.

TODO --- Add Pairwise comparision methodology to justify below numbers used for weightage

Cost Efficiency was assigned the highest weight (20\%) on the basis of budgetary constraints. Usage Scalability and Self-hosting Capabilities were weighted at 15\% and Performance Characteristics, such as translation speed and accuracy, were weighed at 10\% considering it as a trade-off for the project contraints based on client requirements.

\subsubsection{Application Framework Evaluation}

\subsubsection{Comparative Analysis: Spring Boot vs. Node.js}

The framework selection process evaluated two primary candidates against specific criteria relevant to the translation service requirements.

\begin{table}[h!]
\centering
\caption{Application Framework Comparison}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|p{2.5cm}|p{1cm}|p{4cm}|p{3cm}|p{4cm}|}
\hline
\textbf{Criteria} & \textbf{Weight} & \textbf{Spring Boot (Java 21)} & \textbf{Node.js} & \textbf{Selection Rationale} \\
\hline
Type Safety & 15\% & 5 - Strong typing reduces runtime errors & 2 - Dynamic typing increases error risk & Critical for production stability \\
\hline
Concurrency Model & 20\% & 5 - Virtual threads enable millions of concurrent operations & 3 - Single-threaded event loop limitations & Essential for parallel translation processing \\
\hline
Enterprise Features & 10\% & 5 - Comprehensive ecosystem with dependency injection & 3 - Requires third-party package integration & Reduces development complexity \\
\hline
Developer Experience & 10\% & 4 - Traditional synchronous coding paradigm & 3 - Asynchronous-first complexity & Maintainability consideration \\
\hline
Performance & 15\% & 5 - Excellent I/O-bound task handling & 4 - Strong I/O performance but CPU limitations & Translation service is I/O-intensive \\
\hline
\end{tabular}%
}
\end{table}

\textbf{Weighted Score: Spring Boot (4.6/5) vs. Node.js (3.1/5)}

\textbf{Critical Finding:} Springboot with Java 21 came out as a strong candidate for backend service. It perfectly aligned with our objective of handling I/O heavy loads for real time translation. Springboot also provides out of the box configurations for seamlessly creating backend services without writing much of the boilerplate code. With concurrency as our challenge for the backend, Java 21's virtual threads provide more efficiency to handle high traffic requests in multi-threaded environments.

\subsubsection{Translation Engine Evaluation}

The translation engine evaluation process was conducted using the previsously defined multi-criteria decision analysis (MCDA) framework, applying weighted factors to balance cost, usage, self-hosting capability and translation quality. The selected candidates represent the top available machine translation options, spanning towards both open-source and self-hostable solution like LibreTranslate and major cloud based solutions such as DeepL, Google Cloud Translate, and Azure Translator.

\begin{table}[h!]
\centering
\caption{Translation Engine Evaluation Matrix}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|p{2cm}|p{1cm}|p{2.5cm}|p{2cm}|p{2.5cm}|p{2.5cm}|}
\hline
\textbf{Criteria} & \textbf{Weight} & \textbf{LibreTranslate} & \textbf{DeepL} & \textbf{Google Cloud} & \textbf{Azure Translator} \\
\hline
Cost Efficiency & 20\% & 5 - Completely free when self-hosted & 3 - Limited free tier, paid structure & 3 - Paid after quota & 3 - Paid after quota \\
\hline
Usage Limits & 15\% & 5 - No imposed limits, hardware-bound only & 2 - 5,000 chars/request in free tier & 3 - 500k chars/month free & 4 - 2M chars/month free \\
\hline
Self-hosting & 15\% & 5 - Fully self-hostable & 1 - Cloud-only service & 1 - Cloud-only service & 1 - Cloud-only service \\
\hline
Data Privacy & 15\% & 5 - Complete local processing control & 3 - Cloud processing with deletion policies & 3 - Google server processing & 3 - Azure server processing \\
\hline
Translation Quality & 10\% & 3 - Moderate, suitable for tourism content & 5 - Excellent, especially European languages & 4 - High multilingual support & 4 - High multilingual support \\
\hline
\end{tabular}%
}
\end{table}

\textbf{Weighted Scores:} LibreTranslate (4.65/5), DeepL (3.25/5), Google Cloud (3.45/5), Azure (3.55/5)

\textbf{Trade-off Analysis:}
The evaluation process highlighted a key trade-off between translation quality and cost efficiency. By prioritising budgetary contraints and zero recurring costs, we accepted the risk of moderate translation quality when compared to significantly higher costs associated with commercial providers. This risk was mitigated by the observation that the nature of tourism vocabulary comprised largely of common travel-related expressions and predictable phrase sets, making the LibreTranslate's moderate quality rating proved sufficient for practical application needs\cite{libretranslate}. Additionally, LibreTranslate offers built-in translation improvement and correction functionality giving use promising opportunities for further enhancement of translation quality\cite{open-nmt}.






