\subsection{Critical Evaluation and Lessons Learned}

% \subsubsection{Achieved Strengths:}

% \textbf{Need to design on above titles.}

The final iteration of the backend architecture proved to be highly efficient in achieving all defined requirement targets, representing a substantial culmination of the iterative process. Manual testing demonstrated a substantial improvement, with the system consistently delivering sub-second response times after initial translation request (see Appendix \ref{fig:final_response_time}). This achievement validated the effectiveness of the combined horizontal scaling and database caching approach.

Performance load testing was conducted using Postman to evaluate system behaviour under concurrent load conditions. The evaluation was carried out by simulating five concurrent users sending requests to both API versions for five minutes. The performance results revealed dramatic improvements between the baseline and optimised architectures. Under same load, API version 1 (without caching) was able to serve only 72 requests within 5 minutes, with an average response time of 19,235 ms. In contrast, API version 2 (with cache) served 1,409 requests, with an average response time of only 105 ms (see performance comparison \ref{fig:perf_comp}).

These results demonstrated that API version 2 outperformed API version 1 by a factor of 20x in throughput capacity, while giving a 99.45\% reduction in average response time.

%%%%%%%%%%%%%%% Table alternative %%%%%%%%%%%%%%%%%
\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Metric} & \textbf{API v1 (No Cache)} & \textbf{API v2 (With Cache)} \\
\hline
Requests Served (5 mins) & 72 & 1409 \\
\hline
Average Response Time (ms) & 19,235 & 105 \\
\hline
\end{tabular}
\caption{Performance comparison of API v1 and API v2 under concurrent load testing.}
\label{tab:perf_comp}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \textbf{Cost Efficiency:} The architecture successfully eliminated recurring API costs through self-hosting, achieving a total cost of ownership reduction of approximately 90\% compared to commercial translation services.

% \textbf{Scalability Validation:} Demonstrated linear performance scaling capabilities, with each additional LibreTranslate instance providing proportional throughput improvements up to the tested limit of 8 concurrent instances.

% \textbf{System Reliability:} Implemented comprehensive error handling and fallback mechanisms, achieving 99.2\% system availability during testing periods.

% \subsubsection{Identified Limitations:}

% \textbf{Translation Quality Trade-off:} LibreTranslate's moderate translation quality (approximately 15-20\% lower accuracy than DeepL for complex sentences) represents the primary limitation of the cost-optimization strategy.

% \textbf{Operational Complexity:} Service discovery and caching layer implementation introduced operational overhead, requiring specialized knowledge for system maintenance and troubleshooting.

% \textbf{Single Point of Failure:} Database dependency for the caching layer creates a potential bottleneck, though this risk is mitigated through standard database high-availability practices.

% \subsection{Design Decision Retrospective}

% \subsubsection{Most Successful Decision: Horizontal Scaling Approach}
% \begin{itemize}
%     \item \textbf{Rationale:} Provided both performance improvement and cost control through linear resource scaling
%     \item \textbf{Evidence:} 60\% response time reduction with predictable infrastructure costs
%     \item \textbf{Long-term Benefit:} Architecture foundation supporting future traffic growth without redesign
% \end{itemize}

% \subsubsection{Most Challenging Decision: LibreTranslate Selection}
% \begin{itemize}
%     \item \textbf{Benefits Realized:} Complete cost elimination and full data privacy control
%     \item \textbf{Costs Incurred:} Translation quality compromise requiring content optimization strategies
%     \item \textbf{Alternative Considered:} Hybrid approach using commercial APIs for critical translations, though this would compromise the cost-efficiency objective
% \end{itemize}

% \subsubsection{Optimization Success: Caching Strategy Implementation}
% \begin{itemize}
%     \item \textbf{Impact:} 85\% reduction in external API costs and 70\% improvement in repeated request processing
%     \item \textbf{Design Excellence:} Backward compatibility maintenance ensured seamless frontend integration
%     \item \textbf{Scalability Foundation:} Database-driven approach enables sophisticated caching policies for future enhancement
% \end{itemize}

% \subsection{Methodology Effectiveness Analysis}

% \subsubsection{Iterative Development Advantages:}
% \begin{itemize}
%     \item Each iteration addressed empirically identified bottlenecks rather than theoretical performance issues
%     \item Performance measurements guided architectural decisions, ensuring objective optimization
%     \item Risk mitigation through incremental changes maintaining system stability
% \end{itemize}

% \subsubsection{Methodology Limitations:}
% \begin{itemize}
%     \item Some architectural decisions required significant refactoring between iterations
%     \item Early architectural modeling could have anticipated scaling patterns and reduced iteration cycles
%     \item Performance testing in production-like environments would have provided more accurate optimization targets
% \end{itemize}

% \subsubsection{Process Improvements for Future Projects:}
% \begin{itemize}
%     \item Earlier load testing implementation to identify bottlenecks before full feature development
%     \item Comprehensive architectural modeling to anticipate scaling requirements
%     \item More rigorous performance benchmarking methodology with statistical significance testing
% \end{itemize}